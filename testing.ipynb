{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from util import accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# We want to evaluate the test accuracy of the overall performance, the in race perform, and the other race\n",
    "# How? \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "    \n",
    "def accuracy_by_race(output, target, dataset, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        # Initialize a dictionary to hold accuracies for each race\n",
    "        accuracies = defaultdict(list)\n",
    "\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            accuracy_k = correct_k.mul_(100.0 / batch_size)\n",
    "\n",
    "            # Record accuracy for each race\n",
    "            for i in range(batch_size):\n",
    "                race = dataset.classes[target[i]]\n",
    "                accuracies[race].append(accuracy_k[i])\n",
    "\n",
    "        return accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([100.]), tensor([100.])]\n"
     ]
    }
   ],
   "source": [
    "# Define your output tensor and target tensor\n",
    "output = torch.tensor([[0.1, 0.2, 0.7], [0.8, 0.1, 0.1]])\n",
    "target = torch.tensor([2, 0])\n",
    "\n",
    "# Call the accuracy function\n",
    "result = accuracy(output, target, topk=(1,2))\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "\n",
    "\n",
    "def accuracy_by_race(output, target, dataset, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        # Initialize a dictionary to hold accuracies for each race\n",
    "        accuracies = defaultdict(list)\n",
    "\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            accuracy_k = correct_k.mul_(100.0 / batch_size)\n",
    "\n",
    "            # Record accuracy for each race\n",
    "            for i in range(batch_size):\n",
    "                race = dataset.classes[target[i]]\n",
    "                accuracies[race].append(accuracy_k[i])\n",
    "\n",
    "        return accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m dataset\u001b[39m.\u001b[39mclass_to_idx \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mrace1\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrace2\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrace3\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Call the accuracy_by_race function\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m accuracies \u001b[39m=\u001b[39m accuracy_by_race(output, target, dataset, topk\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(accuracies)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Print the accuracies for each race\u001b[39;00m\n",
      "\u001b[1;32m/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_size):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         race \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mclasses[target[i]]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         accuracies[race]\u001b[39m.\u001b[39mappend(accuracy_k[i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m accuracies\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define your output tensor and target tensor\n",
    "output = torch.tensor([[0.1, 0.2, 0.7], [0.8, 0.1, 0.1]])\n",
    "target = torch.tensor([2, 0])\n",
    "\n",
    "# Create a mock dataset with class labels corresponding to races\n",
    "dataset = ImageFolder(root='./test/')\n",
    "dataset.classes = ['race1', 'race2', 'race3']\n",
    "dataset.class_to_idx = {'race1': 0, 'race2': 1, 'race3': 2}\n",
    "\n",
    "# Call the accuracy_by_race function\n",
    "accuracies = accuracy_by_race(output, target, dataset, topk=(1,2))\n",
    "print(accuracies)\n",
    "\n",
    "# Print the accuracies for each race\n",
    "for race, accuracy in accuracies.items():\n",
    "    print(f'Accuracy for {race}: {sum(accuracy)/len(accuracy)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m])  \u001b[39m# Sample target tensor, ground truth labels\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Call the accuracy function\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m top1, top5 \u001b[39m=\u001b[39m accuracy(output, target, topk\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m, \u001b[39m5\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTop-1 Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtop1\u001b[39m.\u001b[39mitem()\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTop-5 Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtop5\u001b[39m.\u001b[39mitem()\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m maxk \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(topk)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m batch_size \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m _, pred \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39;49mtopk(maxk, \u001b[39m1\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mt()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m correct \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39meq(target\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mexpand_as(pred))\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create some sample data\n",
    "output = torch.randn(32, )  # Sample output tensor, 5 samples, 3 classes\n",
    "target = torch.tensor([1, 2, 0, 2, 1])  # Sample target tensor, ground truth labels\n",
    "\n",
    "# Call the accuracy function\n",
    "top1, top5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "print(f\"Top-1 Accuracy: {top1.item():.2f}%\")\n",
    "print(f\"Top-5 Accuracy: {top5.item():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in /Users/nina/Library/Python/3.9/lib/python/site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.1 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: filelock in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1->torchvision) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1->torchvision) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5560, -1.4274, -0.2668, -0.0637, -1.0900],\n",
      "        [ 1.4864, -0.0651,  0.1268,  0.4204, -0.2589],\n",
      "        [ 0.4242, -0.0728,  0.4617, -0.8344,  0.3453],\n",
      "        [-0.3346,  0.2447,  0.3663, -1.8127, -0.4779],\n",
      "        [-1.0697, -0.2619, -0.4329, -0.8537, -0.1789],\n",
      "        [ 1.3182, -1.8663,  0.2477, -0.1045,  0.5833],\n",
      "        [ 0.0652, -0.2209, -1.3188, -1.5880,  0.2209],\n",
      "        [ 1.7836,  0.8594,  1.0216, -0.1526,  0.1906]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.randn(8, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data loader\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "def set_loader(data_folder, batch_size): \n",
    "    input_shape = (3, 128, 128)\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "            transforms.Resize(int(input_shape[1] * 156 / 128)),\n",
    "            transforms.RandomCrop(input_shape[1:]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                            std=[0.5, 0.5, 0.5])\n",
    "        ])  \n",
    "\n",
    "    #assume two crop is not relevant \n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        root=data_folder,\n",
    "        transform=train_transform\n",
    "    )\n",
    "\n",
    "    train_sampler = None\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=(train_sampler is None),\n",
    "        pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "    print(\"train_loader length: \", len(train_loader))\n",
    "\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader length:  750\n"
     ]
    }
   ],
   "source": [
    "train_folder = \"./data/test/African/\"\n",
    "train_loader = set_loader(train_folder, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.randint(0, 500, (8,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[402,  55, 366, 240, 440, 440, 418,  55],\n",
      "        [416, 108,  75, 366, 192, 309, 402, 108],\n",
      "        [129, 314, 197, 190, 486, 154, 355,  23],\n",
      "        [428,  75, 414, 341,  44, 143, 428, 314],\n",
      "        [ 81, 240, 320, 176, 416, 416, 201, 492]]) torch.Size([5, 8])\n",
      "tensor([[262],\n",
      "        [423],\n",
      "        [177],\n",
      "        [429],\n",
      "        [472],\n",
      "        [214],\n",
      "        [155],\n",
      "        [240]]) torch.Size([8, 1])\n",
      "tensor([[262, 262, 262, 262, 262],\n",
      "        [423, 423, 423, 423, 423],\n",
      "        [177, 177, 177, 177, 177],\n",
      "        [429, 429, 429, 429, 429],\n",
      "        [472, 472, 472, 472, 472],\n",
      "        [214, 214, 214, 214, 214],\n",
      "        [155, 155, 155, 155, 155],\n",
      "        [240, 240, 240, 240, 240]]) torch.Size([8, 5])\n",
      "tensor([[False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False]])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "[tensor([0.]), tensor([0.])]\n"
     ]
    }
   ],
   "source": [
    "#randome int of batch size 8, from 500 classes\n",
    "\n",
    "topk = (1,5)\n",
    "batch_size = 8\n",
    "pred = torch.tensor([[402,  55, 366, 240, 440, 440, 418,  55],\n",
    "        [416, 108,  75, 366, 192, 309, 402, 108],\n",
    "        [129, 314, 197, 190, 486, 154, 355,  23],\n",
    "        [428,  75, 414, 341,  44, 143, 428, 314],\n",
    "        [ 81, 240, 320, 176, 416, 416, 201, 492]])\n",
    "print(pred, pred.shape)\n",
    "\n",
    "for idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "    pred = pred.t()\n",
    "    target = target.view(-1, 1)\n",
    "    print(target, target.shape)\n",
    "    target = target.expand_as(pred)\n",
    "    print(target, target.shape)\n",
    "\n",
    "    correct = pred.eq(target)\n",
    "    print(correct)\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        print(correct_k)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    \n",
    "    print(res)\n",
    "    break \n",
    "\n",
    "    # print(idx, data.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True])\n",
      "torch.Size([1])\n",
      "tensor([True])\n",
      "tensor([1.])\n",
      "tensor([True])\n",
      "tensor([ True, False, False, False, False])\n",
      "torch.Size([5])\n",
      "tensor([ True, False, False, False, False])\n",
      "tensor([1.])\n",
      "tensor([ True, False, False, False, False])\n",
      "[tensor([12.5000]), tensor([12.5000])]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "correct = torch.tensor([True, False, False, False, False, False, False, False],\n",
    "                       [False, False, False, False, False, False, False, False],\n",
    "                       [True, False, False, False, False, False, False, False])\n",
    "for k in topk:\n",
    "    print(correct[:k])\n",
    "    print(correct[:k].shape)\n",
    "    print(correct[:k].reshape(-1))\n",
    "    print(correct[:k].reshape(-1).float().sum(0, keepdim=True))\n",
    "    print(correct[:k].view(-1))\n",
    "    correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "    res.append(correct_k.mul_(100.0 / batch_size))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate(val_loader, model, classifier, criterion, opt, class_to_idx):\n",
    "    \"\"\"Validation\"\"\"\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    class_to_idx = val_loader.class_to_idx\n",
    "\n",
    "    \n",
    "\n",
    "    # Create dictionaries to store accuracy by race\n",
    "    race_acc = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (images, labels) in enumerate(val_loader):\n",
    "            images = images.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "\n",
    "            # Forward pass\n",
    "            output = classifier(model.encoder(images))\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # Update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
    "            top1.update(acc1[0], bsz)\n",
    "\n",
    "            # Measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # Group predictions and labels by race\n",
    "            for i in range(bsz):\n",
    "                label = labels[i].item()\n",
    "                predicted_class = output[i].argmax().item()\n",
    "                race = class_to_idx[label]\n",
    "\n",
    "                if race not in race_acc:\n",
    "                    race_acc[race] = AverageMeter()\n",
    "\n",
    "                race_acc[race].update(int(predicted_class == label), 1)\n",
    "\n",
    "            if idx % opt.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                       idx, len(val_loader), batch_time=batch_time,\n",
    "                       loss=losses, top1=top1))\n",
    "\n",
    "    print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "    # Print accuracy by race\n",
    "    for race, acc_meter in race_acc.items():\n",
    "        print(f'Race {race}: Acc@1 {acc_meter.avg:.3f}')\n",
    "\n",
    "    return losses.avg, top1.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'African': 0, 'Asian': 1, 'Caucasian': 2, 'Indian': 3}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main_linear import set_loader\n",
    "class Opt:\n",
    "    def __init__(self, val_folder, batch_size, num_workers, train_folder=None, model='resnet50', n_cls=4, ckpt='./path/to/your/ckpt/model.ckpt'):\n",
    "        self.val_folder = val_folder\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.train_folder = train_folder\n",
    "        self.model = model\n",
    "        self.n_cls = n_cls\n",
    "        self.ckpt = ckpt\n",
    "\n",
    "\n",
    "opt = Opt(val_folder='./data/linear_prob_data/train/', batch_size=32, num_workers=4)\n",
    "_, val_loader = set_loader(opt)\n",
    "class_to_idx = val_loader.dataset.class_to_idx\n",
    "class_to_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from main_linear import set_loader\n",
    "class Opt:\n",
    "    def __init__(self, val_folder, batch_size, num_workers, train_folder=None):\n",
    "        self.val_folder = val_folder\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.train_folder = train_folder\n",
    "\n",
    "opt = Opt(val_folder='./data/biased_african/train/', batch_size=32, num_workers=4)\n",
    "_, val_loader = set_loader(opt)\n",
    "class_to_idx = val_loader.dataset.class_to_idx\n",
    "class_to_idx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "{'African': 0, 'Asian': 1, 'Caucasian': 2, 'Indian': 3}\n",
    "\n",
    "\n",
    "I now want to see how i can modify validate code to record accuracy by race collect to \n",
    "1. Overall performance\n",
    "2. Inrace performance: Same race accuracy. Ex: We have 4 biased models and 1 of them is biased towards African dataset. We want to see just the perfomace on the African.\n",
    "3. Out of race performance: Other race accuracy. Ex: We have 4 biased models and 1 of them is biased towards African dataset. We want to see just the perfomace on the non-African or the performance on the 3 other races.\n",
    "\n",
    "Here is the validation and accuracy code, how would i modify them. I need to class_to_idx to track what inputs I am training on and what the validation is:\n",
    "\n",
    "\n",
    "\n",
    "def validate(val_loader, model, classifier, criterion, opt):\n",
    "    \"\"\"validation\"\"\"\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (images, labels) in enumerate(val_loader):\n",
    "            images = images.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "\n",
    "            # forward\n",
    "            output = classifier(model.encoder(images))\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
    "            top1.update(acc1[0], bsz)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if idx % opt.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                       idx, len(val_loader), batch_time=batch_time,\n",
    "                       loss=losses, top1=top1))\n",
    "\n",
    "    print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "    return losses.avg, top1.avg\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from util import AverageMeter, accuracy\n",
    "import time\n",
    "\n",
    "def validate(val_loader, model, classifier, criterion, opt, class_to_idx):\n",
    "    \"\"\"Validation\"\"\"\n",
    "    # model.eval()\n",
    "    # classifier.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    race_accuracies = {}  # Store accuracy by race\n",
    "    in_race_accuracies = {}  # Store in-race accuracy\n",
    "    out_of_race_accuracies = {}  # Store out-of-race accuracy\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (images, labels) in enumerate(val_loader):\n",
    "            images = images.float()\n",
    "            labels = labels\n",
    "            bsz = labels.shape[0]\n",
    "            # Debugging print: Print images, labels, and batch size\n",
    "            print(f'Batch {idx} - Images: {images.shape}, Labels: {labels.shape}, Batch Size: {bsz}')\n",
    "\n",
    "            # Check the shape of labels\n",
    "            print(f'Labels Shape: {labels.shape}')\n",
    "            # Calculate the race for each image based on class labels\n",
    "            race_labels = [k for k, v in class_to_idx.items() if v in labels]\n",
    "            race_labels = []\n",
    "            for k, v in class_to_idx.items():\n",
    "                print(k)\n",
    "                print(v)\n",
    "\n",
    "\n",
    "                if v in labels:\n",
    "                    race_labels.append(k)\n",
    "            print(f'Race Labels: {race_labels}')\n",
    "\n",
    "            return\n",
    "\n",
    "            # Debugging print: Print the current batch index and batch size\n",
    "            # Forward pass\n",
    "            # output = classifier(model.encoder(images))  # Commented out the encoder part\n",
    "            output = classifier(images)  # Assuming 'classifier' is appropriate for the task\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # Debugging print: Print the loss and accuracy for this batch\n",
    "            print(f'Loss: {loss.item()}, Accuracy: {accuracy(output, labels)}')\n",
    "\n",
    "            # Update metrics\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1, _ = accuracy(output, labels, topk=(1, 5))\n",
    "            top1.update(acc1, bsz)\n",
    "\n",
    "            # Debugging print: Print the updated metrics\n",
    "            print(f'Updated Loss: {losses.avg}, Updated Accuracy: {top1.avg}')\n",
    "\n",
    "            # Calculate accuracy by race\n",
    "            for race in race_labels:\n",
    "                if race not in race_accuracies:\n",
    "                    race_accuracies[race] = AverageMeter()\n",
    "                race_accuracies[race].update(acc1, bsz)\n",
    "\n",
    "            # Debugging print: Print accuracy by race\n",
    "            print(f'Accuracy by Race: {race_accuracies}')\n",
    "\n",
    "            # Measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                       idx, len(val_loader), batch_time=batch_time,\n",
    "                       loss=losses, top1=top1))\n",
    "\n",
    "    print(' * Overall Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "    # Calculate in-race and out-of-race accuracy\n",
    "    for race, accuracy_meter in race_accuracies.items():\n",
    "        in_race_acc = accuracy_meter.avg\n",
    "        out_of_race_acc = (top1.avg * bsz - accuracy_meter.sum) / (bsz - accuracy_meter.count)\n",
    "        in_race_accuracies[race] = in_race_acc\n",
    "        out_of_race_accuracies[race] = out_of_race_acc\n",
    "\n",
    "        # Debugging print: Print in-race and out-of-race accuracy\n",
    "        print(f'In-Race Accuracy ({race}): {in_race_acc:.3f}')\n",
    "        print(f'Out-of-Race Accuracy ({race}): {out_of_race_acc:.3f}')\n",
    "\n",
    "    # Debugging print: Print the final accuracy results\n",
    "    print(f'Final Loss: {losses.avg}, Final Accuracy: {top1.avg}')\n",
    "    print(f'Final In-Race Accuracy: {in_race_accuracies}')\n",
    "    print(f'Final Out-of-Race Accuracy: {out_of_race_accuracies}')\n",
    "\n",
    "    return losses.avg, top1.avg, in_race_accuracies, out_of_race_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from main_linear import set_loader  # Replace with your actual data loader module\n",
    "from networks.resnet_big import LinearClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from networks.resnet_big import SupConResNet, LinearClassifier\n",
    "\n",
    "def set_model(opt):\n",
    "    model = SupConResNet(name=opt.model)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    classifier = LinearClassifier(name=opt.model, num_classes=opt.n_cls)\n",
    "\n",
    "    ckpt = torch.load(opt.ckpt, map_location='cpu')\n",
    "    state_dict = ckpt['model']\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model.encoder = torch.nn.DataParallel(model.encoder)\n",
    "        else:\n",
    "            new_state_dict = {}\n",
    "            # for k, v in state_dict.items():\n",
    "            #     k = k.replace(\"module.\", \"\")\n",
    "            #     new_state_dict[k] = v\n",
    "            # state_dict = new_state_dict\n",
    "            # model = model.cuda()\n",
    "            # classifier = classifier.cuda()\n",
    "            # criterion = criterion.cuda()\n",
    "            # cudnn.benchmark = True\n",
    "\n",
    "        # model.load_state_dict(state_dict)\n",
    "    else:\n",
    "        print(\"GPU not available. Using CPU for inference.\")\n",
    "        model.load_state_dict(state_dict, map_location='cpu')\n",
    "\n",
    "    return model, classifier, criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the Opt object\n",
    "class Opt:\n",
    "    def __init__(self, val_folder, batch_size, num_workers, train_folder=None):\n",
    "        self.val_folder = val_folder\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.train_folder = train_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzomendoza/anaconda3/envs/machinelearning/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/lorenzomendoza/anaconda3/envs/machinelearning/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 - Images: torch.Size([10, 3, 400, 400]), Labels: torch.Size([10]), Batch Size: 10\n",
      "Labels Shape: torch.Size([10])\n",
      "African\n",
      "0\n",
      "Asian\n",
      "1\n",
      "Caucasian\n",
      "2\n",
      "Indian\n",
      "3\n",
      "Race Labels: ['African']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m small_val_loader\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39msamples \u001b[39m=\u001b[39m small_val_loader\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39msamples[:num_samples_to_test]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Call the modified validate function with the small test dataset\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss, overall_accuracy, in_race_accuracies, out_of_race_accuracies \u001b[39m=\u001b[39m validate(val_loader, model, classifier, criterion, opt, class_to_idx)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# # Print the results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# print(f'Overall Accuracy: {overall_accuracy:.3f}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# for race, in_race_acc in in_race_accuracies.items():\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#     print(f'In-Race Accuracy ({race}): {in_race_acc:.3f}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m#     print(f'Out-of-Race Accuracy ({race}): {out_of_race_accuracies[race]:.3f}')\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from main_linear import set_loader  # Replace with your actual data loader module\n",
    "from networks.resnet_big import LinearClassifier\n",
    "# Load your model and data loaders\n",
    "# model = models.resnet50(pretrained=True)\n",
    "# classifier = nn.Linear(2048, 4)  # Replace with your classifier architecture\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "opt = Opt(val_folder='./data/linear_prob_data/train/', batch_size=32, num_workers=4)\n",
    "\n",
    "# Load the data loader\n",
    "_, val_loader = set_loader(opt)\n",
    "\n",
    "# Define class_to_idx based on your dataset\n",
    "class_to_idx = {'African': 0, 'Asian': 1, 'Caucasian': 2, 'Indian': 3}\n",
    "# Iterate through the small validation data loader and print labels\n",
    "# for idx, (images, labels) in enumerate(val_loader):\n",
    "#     print(f'Batch {idx} - Labels: {labels}')\n",
    "\n",
    "\n",
    "# Create a small test dataset by taking the first N samples from the validation set\n",
    "num_samples_to_test = 10  # Adjust this number as needed\n",
    "small_val_loader = torch.utils.data.DataLoader(val_loader.dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n",
    "small_val_loader.dataset.samples = small_val_loader.dataset.samples[:num_samples_to_test]\n",
    "\n",
    "# Call the modified validate function with the small test dataset\n",
    "loss, overall_accuracy, in_race_accuracies, out_of_race_accuracies = validate(val_loader, None, None, None, opt, class_to_idx)\n",
    "\n",
    "# # Print the results\n",
    "# print(f'Overall Accuracy: {overall_accuracy:.3f}')\n",
    "# for race, in_race_acc in in_race_accuracies.items():\n",
    "#     print(f'In-Race Accuracy ({race}): {in_race_acc:.3f}')\n",
    "#     print(f'Out-of-Race Accuracy ({race}): {out_of_race_accuracies[race]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i then want to those image_name,id,race,split\n",
    "60-FaceId-0_align.jpg,m.07h5rn,0,test\n",
    "62-FaceId-0_align.jpg,m.07h5rn,0,test\n",
    "18-FaceId-0_align.jpg,m.07h5rn,0,test\n",
    "19-FaceId-0_align.jpg,m.07h5rn,0,test\n",
    "32-FaceId-0_align.jpg,m.07h5rn,0,test\n",
    "50-FaceId-0_align.jpg,m.07h5rn,0,test\n",
    "52-FaceId-0_align.jpg,m.07h5rn,0,test\n",
    "101-FaceId-0_align.jpg,m.07h5rn,0,test\n",
    "11-FaceId-0_align.jpg,m.07h5rn,0,test\n",
    "35-FaceId-0_align.jpg,m.07h5rn,0,test\n",
    "74-FaceId-0_align.jpg,m.07h5rn,0,test\n",
    "78-FaceId-0_align.jpg,m.07h5rn,0,test\n",
    "37-FaceId-0_align.jpg,m.07h5rn,0,train\n",
    "85-FaceId-0_align.jpg,m.07h5rn,0,train\n",
    "66-FaceId-0_align.jpg,m.07h5rn,0,train\n",
    "106-FaceId-0_align.jpg,m.07h5rn,0,train\n",
    "44-FaceId-0_align.jpg,m.07h5rn,0,train\n",
    "63-FaceId-0_align.jpg,m.07h5rn,0,train\n",
    "55-FaceId-0_align.jpg,m.07h5rn,0,train\n",
    "70-FaceId-1_align.jpg,m.07h5rn,0,train\n",
    "97-FaceId-0_align.jpg,m.07h5rn,0,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Helpe me do this: Now that we have the mapping from the labels to the races, we now want to track the performance of the accuracy on the races that the ids that were in the batch. \n",
    "To do this, we need to use label_to_race_mapping. target contains the labels for the true id of the images. label_to_race_mapping maps has the labels as keys mapping to it's race. \n",
    "After we get the Prediction and compare them to the targets to make correct, we should see how each race did from the labels of \n",
    "\n",
    "Prediction: tensor([[  0,   3,   1,   2, 398],\n",
    "        [  0,   3,   1,   2, 398],\n",
    "        [  0,   3,   1,   2, 325],\n",
    "        [  0,   3,   1,   2, 355],\n",
    "        [  0,   3,   1,   2, 355],\n",
    "        [  0,   3,   1,   2, 227],\n",
    "        [  0,   3,   1,   2, 355],\n",
    "        [  0,   3,   1,   2, 341],\n",
    "        [  0,   3,   1,   2, 212],\n",
    "        [  0,   3,   1,   2, 227],\n",
    "        [  0,   3,   1,   2, 341],\n",
    "        [  0,   3,   1,   2, 212],\n",
    "        [  0,   3,   1,   2, 398],\n",
    "        [  0,   3,   1,   2, 341],\n",
    "        [  0,   3,   1,   2, 341],\n",
    "        [  0,   3,   1,   2, 341]], device='cuda:0')\n",
    "Prediction T: tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "           0,   0],\n",
    "        [  3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n",
    "           3,   3],\n",
    "        [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
    "           1,   1],\n",
    "        [  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
    "           2,   2],\n",
    "        [398, 398, 325, 355, 355, 227, 355, 341, 212, 227, 341, 212, 398, 341,\n",
    "         341, 341]], device='cuda:0')\n",
    "target_viewed T: tensor([[0, 2, 2, 3, 2, 3, 0, 2, 1, 3, 1, 2, 3, 0, 1, 1]], device='cuda:0')\n",
    "target_expand_pred T: tensor([[0, 2, 2, 3, 2, 3, 0, 2, 1, 3, 1, 2, 3, 0, 1, 1],\n",
    "        [0, 2, 2, 3, 2, 3, 0, 2, 1, 3, 1, 2, 3, 0, 1, 1],\n",
    "        [0, 2, 2, 3, 2, 3, 0, 2, 1, 3, 1, 2, 3, 0, 1, 1],\n",
    "        [0, 2, 2, 3, 2, 3, 0, 2, 1, 3, 1, 2, 3, 0, 1, 1],\n",
    "        [0, 2, 2, 3, 2, 3, 0, 2, 1, 3, 1, 2, 3, 0, 1, 1]], device='cuda:0')\n",
    "correct: tensor([[ True, False, False, False, False, False,  True, False, False, False,\n",
    "         False, False, False,  True, False, False],\n",
    "        [False, False, False,  True, False,  True, False, False, False,  True,\n",
    "         False, False,  True, False, False, False],\n",
    "        [False, False, False, False, False, False, False, False,  True, False,\n",
    "          True, False, False, False,  True,  True],\n",
    "        [False,  True,  True, False,  True, False, False,  True, False, False,\n",
    "         False,  True, False, False, False, False],\n",
    "        [False, False, False, False, False, False, False, False, False, False,\n",
    "         False, False, False, False, False, False]], device='cuda:0')\n",
    "k: 1\n",
    "correct_k: tensor([3.], device='cuda:0')\n",
    "k: 5\n",
    "correct_k: tensor([16.], device='cuda:0')\n",
    "\n",
    "\n",
    "def accuracy(output, target, label_to_race_mapping ,topk=(1,)): # Need to add label_to_race_mapping PARAM\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k, and records accuracy by race\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        print(f\"Prediction: {pred}\")\n",
    "        pred = pred.t()\n",
    "        print(f\"Prediction T: {pred}\")\n",
    "\n",
    "        target_viewed = target.view(1, -1)\n",
    "        print(f\"target_viewed T: {target_viewed}\")\n",
    "\n",
    "        target_expand_pred = target_viewed.expand_as(pred)\n",
    "        print(f\"target_expand_pred T: {target_expand_pred}\")\n",
    "\n",
    "        correct = pred.eq(target_expand_pred)\n",
    "        print(f\"correct: {correct}\")\n",
    "\n",
    "        res = []\n",
    "        for k in topk: \n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size)) # Right now \n",
    "        return res\n",
    "\n",
    "def label_to_race(labels, id_to_idx, class_to_race):\n",
    "    id_list = labels.tolist() \n",
    "    print(f\"id_list: {id_list}\")\n",
    "\n",
    "    # this is a list of id is the image from, 0 (e.g., 'm.0181j_'), and the remaining 4 images belong to class 1 (e.g., 'm.01lb8z').\n",
    "    # id_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "    \n",
    "    class_labels = [class_label for idx in id_list for class_label, class_idx in id_to_idx.items() if class_idx == idx] # Get the list of corresponding ids that the images are from\n",
    "    # id_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "    # -> Class: ['m.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.01lb8z', 'm.01lb8z', 'm.01lb8z', 'm.01lb8z']\n",
    "    races = [class_to_race[class_label] for class_label in class_labels] # Now map the ids to the race from the csv\n",
    "    print(f\"Class: {class_labels}\")\n",
    "    print(f\"Races: {races}\")\n",
    "    # Create a dictionary mapping labels to their corresponding races\n",
    "    label_to_race_mapping = dict(zip(id_list, races))\n",
    "    print(f\"Label-to-Race{label_to_race_mapping}\")\n",
    "\n",
    "    return label_to_race_mapping\n",
    "    \n",
    "\n",
    "def validate(val_loader, model, classifier, criterion, opt):\n",
    "    \"\"\"validation\"\"\"\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    id_to_idx = val_loader.dataset.class_to_idx # map of id to indices in the val set\n",
    "    print(f\"id_to_idx: {id_to_idx}\")\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # Read the CSV file and create a mapping from class labels to races\n",
    "    class_to_race = {} \n",
    "    with open('data.csv', 'r') as csvfile:\n",
    "        csvreader = csv.DictReader(csvfile)\n",
    "        for row in csvreader:\n",
    "            class_to_race[row['id']] = row['race']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (images, labels) in enumerate(val_loader):\n",
    "            images = images.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            races = label_to_race(labels, id_to_idx, class_to_race)\n",
    "\n",
    "            bsz = labels.shape[0]\n",
    "\n",
    "            # forward\n",
    "            output = classifier(model.encoder(images))\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
    "            top1.update(acc1[0], bsz)\n",
    "\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if idx % opt.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                       idx, len(val_loader), batch_time=batch_time,\n",
    "                       loss=losses, top1=top1))\n",
    "\n",
    "    print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "    return losses.avg, top1.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pandas as pd\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from util import AverageMeter\n",
    "from util import adjust_learning_rate, warmup_learning_rate, accuracy\n",
    "from util import set_optimizer\n",
    "from networks.resnet_big import SupConResNet, LinearClassifier\n",
    "\n",
    "try:\n",
    "    import apex\n",
    "    from apex import amp, optimizers\n",
    "except ImportError:\n",
    "    pass\n",
    "'''\n",
    "python3 main_linear.py --batch_size 16 --num_workers 8 --learning_rate 0.5 --epochs 2 --cosine --dataset path --train_folder ./data/train --val_folder ./data/test/African --cur_race African --n_cls 500\n",
    "'''\n",
    "\n",
    "def parse_option():\n",
    "    parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "    parser.add_argument('--print_freq', type=int, default=10,\n",
    "                        help='print frequency')\n",
    "    parser.add_argument('--save_freq', type=int, default=50,\n",
    "                        help='save frequency')\n",
    "    parser.add_argument('--batch_size', type=int, default=256,\n",
    "                        help='batch_size')\n",
    "    parser.add_argument('--num_workers', type=int, default=8,\n",
    "                        help='num of workers to use')\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help='number of training epochs')\n",
    "\n",
    "    # optimization\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.1,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--lr_decay_epochs', type=str, default='60,75,90',\n",
    "                        help='where to decay lr, can be a list')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=0.2,\n",
    "                        help='decay rate for learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0,\n",
    "                        help='weight decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "\n",
    "    # model dataset\n",
    "    parser.add_argument('--model', type=str, default='resnet50')\n",
    "    parser.add_argument('--dataset', type=str, default='path',\n",
    "                        choices=['path', 'cifar10', 'cifar100'], help='dataset')\n",
    "    parser.add_argument('--n_cls', type=int, help='number of classes')\n",
    "    parser.add_argument('--train_folder', type=str, help='path to train folder')\n",
    "    parser.add_argument('--val_folder', type=str, help='path to val folder')\n",
    "    parser.add_argument('--cur_race', type=str, choices=['Caucasian', 'African', 'Asian', 'Indian'], help=\"enter race currently testing\")\n",
    "\n",
    "    # other setting\n",
    "    parser.add_argument('--cosine', action='store_true',\n",
    "                        help='using cosine annealing')\n",
    "    parser.add_argument('--warm', action='store_true',\n",
    "                        help='warm-up for large batch training')\n",
    "\n",
    "    parser.add_argument('--ckpt', type=str, default='',\n",
    "                        help='path to pre-trained model')\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "\n",
    "    # set the path according to the environment\n",
    "    # opt.data_folder = './datasets/'\n",
    "\n",
    "    iterations = opt.lr_decay_epochs.split(',')\n",
    "    opt.lr_decay_epochs = list([])\n",
    "    for it in iterations:\n",
    "        opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "    opt.model_name = '{}_{}_lr_{}_decay_{}_bsz_{}'.\\\n",
    "        format(opt.dataset, opt.model, opt.learning_rate, opt.weight_decay,\n",
    "               opt.batch_size)\n",
    "\n",
    "    if opt.cosine:\n",
    "        opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "\n",
    "    # warm-up for large-batch training,\n",
    "    if opt.warm:\n",
    "        opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "        opt.warmup_from = 0.01\n",
    "        opt.warm_epochs = 10\n",
    "        if opt.cosine:\n",
    "            eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "            opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
    "                    1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
    "        else:\n",
    "            opt.warmup_to = opt.learning_rate\n",
    "\n",
    "    if opt.dataset == 'path':\n",
    "        assert opt.train_folder is not None \\\n",
    "            and opt.val_folder is not None \\\n",
    "            and opt.n_cls is not None \\\n",
    "            and opt.cur_race is not None\n",
    "\n",
    "    return opt\n",
    "\n",
    "def set_loader(opt):\n",
    "    #get train and val loader\n",
    "    input_shape = [3, 128, 128]\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(int(input_shape[1] * 156 / 128)),\n",
    "        transforms.RandomCrop(input_shape[1:]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                        std=[0.5, 0.5, 0.5])\n",
    "    ])  \n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                        std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    if opt.train_folder is not None:\n",
    "        train_dataset = datasets.ImageFolder(\n",
    "            root=opt.train_folder,\n",
    "            transform=train_transform\n",
    "        )\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=opt.batch_size, shuffle=True,\n",
    "            num_workers=opt.num_workers, pin_memory=True)\n",
    "    else:\n",
    "        train_loader = None\n",
    "\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        root=opt.val_folder,\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=opt.batch_size, shuffle=False,\n",
    "        num_workers=opt.num_workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "def set_model(opt):\n",
    "    model = SupConResNet(name=opt.model)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    classifier = LinearClassifier(name=opt.model, num_classes=opt.n_cls)\n",
    "\n",
    "    # Check if the checkpoint file exists\n",
    "    if os.path.isfile(opt.ckpt):\n",
    "        ckpt = torch.load(opt.ckpt, map_location='cpu')\n",
    "        state_dict = ckpt['model']\n",
    "    else:\n",
    "        print(f\"No checkpoint found at {opt.ckpt}\")\n",
    "        state_dict = None\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model.encoder = torch.nn.DataParallel(model.encoder)\n",
    "        elif state_dict is not None:  # Add this line\n",
    "            new_state_dict = {}\n",
    "            for k, v in state_dict.items():\n",
    "                k = k.replace(\"module.\", \"\")\n",
    "                new_state_dict[k] = v\n",
    "            state_dict = new_state_dict\n",
    "        model = model.cuda()\n",
    "        classifier = classifier.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "        # Load the state dict only if it is not None\n",
    "        if state_dict is not None:\n",
    "            model.load_state_dict(state_dict)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError('This code requires GPU')\n",
    "\n",
    "    return model, classifier, criterion\n",
    "\n",
    "\n",
    "\n",
    "def train(train_loader, model, classifier, criterion, optimizer, epoch, opt):\n",
    "    \"\"\"one epoch training\"\"\"\n",
    "    model.eval()\n",
    "    classifier.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, (images, labels) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        images = images.cuda(non_blocking=True)\n",
    "        labels = labels.cuda(non_blocking=True)\n",
    "        bsz = labels.shape[0]\n",
    "\n",
    "        # warm-up learning rate\n",
    "        warmup_learning_rate(opt, epoch, idx, len(train_loader), optimizer)\n",
    "\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            features = model.encoder(images)\n",
    "        output = classifier(features.detach())\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # update metric\n",
    "        losses.update(loss.item(), bsz)\n",
    "        acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
    "        top1.update(acc1[0], bsz)\n",
    "\n",
    "        # SGD\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # print info\n",
    "        if (idx + 1) % opt.print_freq == 0:\n",
    "            print('Train: [{0}][{1}/{2}]\\t'\n",
    "                  'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
    "                  'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                   epoch, idx + 1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    return losses.avg, top1.avg\n",
    "\n",
    "\n",
    "def label_to_race(labels, id_to_idx, class_to_race):\n",
    "    id_list = labels.tolist() \n",
    "    # print(f\"id_list: {id_list}\")\n",
    "\n",
    "    # this is a list of id is the image from, 0 (e.g., 'm.0181j_'), and the remaining 4 images belong to class 1 (e.g., 'm.01lb8z').\n",
    "    # id_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "    \n",
    "    class_labels = [class_label for idx in id_list for class_label, class_idx in id_to_idx.items() if class_idx == idx] # Get the list of corresponding ids that the images are from\n",
    "    # id_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "    # -> Class: ['m.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.01lb8z', 'm.01lb8z', 'm.01lb8z', 'm.01lb8z']\n",
    "    races = [class_to_race[class_label] for class_label in class_labels] # Now map the ids to the race from the csv\n",
    "    # print(f\"Class: {class_labels}\")\n",
    "    # print(f\"Races: {races}\")\n",
    "    # Create a dictionary mapping labels to their corresponding races\n",
    "    label_to_race_mapping = dict(zip(id_list, races))\n",
    "    # print(f\"Label-to-Race{label_to_race_mapping}\")\n",
    "\n",
    "    return label_to_race_mapping\n",
    "\n",
    "import csv\n",
    "def validate(val_loader, model, classifier, criterion, opt):\n",
    "    \"\"\"validation\"\"\"\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    id_to_idx = val_loader.dataset.class_to_idx # map of id to indices in the val set\n",
    "    # print(f\"id_to_idx: {id_to_idx}\")\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # Read the CSV file and create a mapping from class labels to races\n",
    "    class_to_race = {} \n",
    "    with open('./data/linear_prob_dataset_split.csv', 'r') as csvfile:\n",
    "        csvreader = csv.DictReader(csvfile)\n",
    "        for row in csvreader:\n",
    "            class_to_race[row['id']] = row['race']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (images, labels) in enumerate(val_loader):\n",
    "            images = images.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            labels_to_races = label_to_race(labels, id_to_idx, class_to_race)\n",
    "\n",
    "            bsz = labels.shape[0]\n",
    "            # print(f'Batch {idx} - Images: {images.shape}, Labels: {labels.shape}, Batch Size: {bsz}')\n",
    "\n",
    "            # forward\n",
    "            output = classifier(model.encoder(images))\n",
    "            loss = criterion(output, labels)\n",
    "            # print(f'labels: {labels}')\n",
    "\n",
    "            # print(f'Output: {output}')\n",
    "\n",
    "            # update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            # acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
    "            print(f\"labels_to_races: {labels_to_races}\")\n",
    "            acc1, accuracy_by_race = accuracy(output, labels, topk=(1,), label_to_race_mapping = labels_to_races)\n",
    "                # accuracy_by_race = {race: correct / total if total > 0 else 0 \n",
    "                #         for race, correct, total in zip(correct_by_race.keys(), correct_by_race.values(), total_by_race.values())}\n",
    "\n",
    "            top1.update(acc1[0][0], bsz)\n",
    "            # print(acc1[0][0])\n",
    "            print(f\"accuracy_by_race: {accuracy_by_race}\")\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if idx % opt.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                      idx, len(val_loader), batch_time=batch_time,\n",
    "                      loss=losses, top1=top1))\n",
    "                for race, acc in accuracy_by_race.items():\n",
    "                    print(f'Accuracy for {race}: {acc:.3f}')\n",
    "\n",
    "\n",
    "    print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "    \n",
    "    return losses.avg, top1.avg\n",
    "\n",
    "\n",
    "def main():\n",
    "    best_acc = 0\n",
    "    opt = parse_option()\n",
    "\n",
    "    # build data loader\n",
    "    train_loader, val_loader = set_loader(opt)\n",
    "\n",
    "    # build model and criterion\n",
    "    model, classifier, criterion = set_model(opt)\n",
    "\n",
    "    # build optimizer\n",
    "    optimizer = set_optimizer(opt, classifier)\n",
    "\n",
    "    # training routine\n",
    "    for epoch in range(1, opt.epochs + 1):\n",
    "        adjust_learning_rate(opt, optimizer, epoch)\n",
    "\n",
    "        # train for one epoch\n",
    "        time1 = time.time()\n",
    "        loss, acc = train(train_loader, model, classifier, criterion,\n",
    "                          optimizer, epoch, opt)\n",
    "        time2 = time.time()\n",
    "        print('Train epoch {}, total time {:.2f}, accuracy: {:.2f}'.format(\n",
    "            epoch, time2 - time1, acc))\n",
    "\n",
    "        # eval for one epoch\n",
    "        loss, val_acc = validate(val_loader, model, classifier, criterion, opt)\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "\n",
    "        # Save checkpoint after each epoch\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_acc': best_acc,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, 'checkpoint_epoch_{}.pth'.format(epoch))\n",
    "\n",
    "    print('best accuracy: {:.2f}'.format(best_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "id_to_idx: {'m.0181j_': 0, 'm.01lb8z': 1, 'm.020skv': 2, 'm.0240pk': 3, 'm.03tjn_': 4, 'm.07h5rn': 5, 'm.09d6n9': 6, 'm.09fdg1': 7, 'm.0bb8pbs': 8, 'm.0cc99yf': 9}\n",
    "id_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "Class: ['m.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.01lb8z', 'm.01lb8z', 'm.01lb8z', 'm.01lb8z']\n",
    "Races: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def label_to_race(labels, id_to_idx, class_to_race):\n",
    "    id_list = labels.tolist() \n",
    "    print(f\"id_list: {id_list}\")\n",
    "\n",
    "    # this is a list of id is the image from, 0 (e.g., 'm.0181j_'), and the remaining 4 images belong to class 1 (e.g., 'm.01lb8z').\n",
    "    # id_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "    \n",
    "    class_labels = [class_label for idx in id_list for class_label, class_idx in id_to_idx.items() if class_idx == idx] # Get the list of corresponding ids that the images are from\n",
    "    # id_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "    # -> Class: ['m.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.0181j_', 'm.01lb8z', 'm.01lb8z', 'm.01lb8z', 'm.01lb8z']\n",
    "    races = [class_to_race[class_label] for class_label in class_labels] # Now map the ids to the race from the csv\n",
    "    print(f\"Class: {class_labels}\")\n",
    "    print(f\"Races: {races}\")\n",
    "    return races"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
