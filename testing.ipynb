{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from util import accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# We want to evaluate the test accuracy of the overall performance, the in race perform, and the other race\n",
    "# How? \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "    \n",
    "def accuracy_by_race(output, target, dataset, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        # Initialize a dictionary to hold accuracies for each race\n",
    "        accuracies = defaultdict(list)\n",
    "\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            accuracy_k = correct_k.mul_(100.0 / batch_size)\n",
    "\n",
    "            # Record accuracy for each race\n",
    "            for i in range(batch_size):\n",
    "                race = dataset.classes[target[i]]\n",
    "                accuracies[race].append(accuracy_k[i])\n",
    "\n",
    "        return accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([100.]), tensor([100.])]\n"
     ]
    }
   ],
   "source": [
    "# Define your output tensor and target tensor\n",
    "output = torch.tensor([[0.1, 0.2, 0.7], [0.8, 0.1, 0.1]])\n",
    "target = torch.tensor([2, 0])\n",
    "\n",
    "# Call the accuracy function\n",
    "result = accuracy(output, target, topk=(1,2))\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "\n",
    "\n",
    "def accuracy_by_race(output, target, dataset, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        # Initialize a dictionary to hold accuracies for each race\n",
    "        accuracies = defaultdict(list)\n",
    "\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            accuracy_k = correct_k.mul_(100.0 / batch_size)\n",
    "\n",
    "            # Record accuracy for each race\n",
    "            for i in range(batch_size):\n",
    "                race = dataset.classes[target[i]]\n",
    "                accuracies[race].append(accuracy_k[i])\n",
    "\n",
    "        return accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m dataset\u001b[39m.\u001b[39mclass_to_idx \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mrace1\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrace2\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrace3\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Call the accuracy_by_race function\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m accuracies \u001b[39m=\u001b[39m accuracy_by_race(output, target, dataset, topk\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(accuracies)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Print the accuracies for each race\u001b[39;00m\n",
      "\u001b[1;32m/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_size):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         race \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mclasses[target[i]]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         accuracies[race]\u001b[39m.\u001b[39mappend(accuracy_k[i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m accuracies\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define your output tensor and target tensor\n",
    "output = torch.tensor([[0.1, 0.2, 0.7], [0.8, 0.1, 0.1]])\n",
    "target = torch.tensor([2, 0])\n",
    "\n",
    "# Create a mock dataset with class labels corresponding to races\n",
    "dataset = ImageFolder(root='./test/')\n",
    "dataset.classes = ['race1', 'race2', 'race3']\n",
    "dataset.class_to_idx = {'race1': 0, 'race2': 1, 'race3': 2}\n",
    "\n",
    "# Call the accuracy_by_race function\n",
    "accuracies = accuracy_by_race(output, target, dataset, topk=(1,2))\n",
    "print(accuracies)\n",
    "\n",
    "# Print the accuracies for each race\n",
    "for race, accuracy in accuracies.items():\n",
    "    print(f'Accuracy for {race}: {sum(accuracy)/len(accuracy)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m])  \u001b[39m# Sample target tensor, ground truth labels\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Call the accuracy function\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m top1, top5 \u001b[39m=\u001b[39m accuracy(output, target, topk\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m, \u001b[39m5\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTop-1 Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtop1\u001b[39m.\u001b[39mitem()\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTop-5 Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtop5\u001b[39m.\u001b[39mitem()\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m maxk \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(topk)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m batch_size \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m _, pred \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39;49mtopk(maxk, \u001b[39m1\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mt()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m correct \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39meq(target\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mexpand_as(pred))\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create some sample data\n",
    "output = torch.randn(32, )  # Sample output tensor, 5 samples, 3 classes\n",
    "target = torch.tensor([1, 2, 0, 2, 1])  # Sample target tensor, ground truth labels\n",
    "\n",
    "# Call the accuracy function\n",
    "top1, top5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "print(f\"Top-1 Accuracy: {top1.item():.2f}%\")\n",
    "print(f\"Top-5 Accuracy: {top5.item():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in /Users/nina/Library/Python/3.9/lib/python/site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.1 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: filelock in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1->torchvision) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1->torchvision) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nina/Library/Python/3.9/lib/python/site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5560, -1.4274, -0.2668, -0.0637, -1.0900],\n",
      "        [ 1.4864, -0.0651,  0.1268,  0.4204, -0.2589],\n",
      "        [ 0.4242, -0.0728,  0.4617, -0.8344,  0.3453],\n",
      "        [-0.3346,  0.2447,  0.3663, -1.8127, -0.4779],\n",
      "        [-1.0697, -0.2619, -0.4329, -0.8537, -0.1789],\n",
      "        [ 1.3182, -1.8663,  0.2477, -0.1045,  0.5833],\n",
      "        [ 0.0652, -0.2209, -1.3188, -1.5880,  0.2209],\n",
      "        [ 1.7836,  0.8594,  1.0216, -0.1526,  0.1906]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.randn(8, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data loader\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "def set_loader(data_folder, batch_size): \n",
    "    input_shape = (3, 128, 128)\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "            transforms.Resize(int(input_shape[1] * 156 / 128)),\n",
    "            transforms.RandomCrop(input_shape[1:]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                            std=[0.5, 0.5, 0.5])\n",
    "        ])  \n",
    "\n",
    "    #assume two crop is not relevant \n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        root=data_folder,\n",
    "        transform=train_transform\n",
    "    )\n",
    "\n",
    "    train_sampler = None\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=(train_sampler is None),\n",
    "        pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "    print(\"train_loader length: \", len(train_loader))\n",
    "\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader length:  750\n"
     ]
    }
   ],
   "source": [
    "train_folder = \"./data/test/African/\"\n",
    "train_loader = set_loader(train_folder, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.randint(0, 500, (8,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[402,  55, 366, 240, 440, 440, 418,  55],\n",
      "        [416, 108,  75, 366, 192, 309, 402, 108],\n",
      "        [129, 314, 197, 190, 486, 154, 355,  23],\n",
      "        [428,  75, 414, 341,  44, 143, 428, 314],\n",
      "        [ 81, 240, 320, 176, 416, 416, 201, 492]]) torch.Size([5, 8])\n",
      "tensor([[262],\n",
      "        [423],\n",
      "        [177],\n",
      "        [429],\n",
      "        [472],\n",
      "        [214],\n",
      "        [155],\n",
      "        [240]]) torch.Size([8, 1])\n",
      "tensor([[262, 262, 262, 262, 262],\n",
      "        [423, 423, 423, 423, 423],\n",
      "        [177, 177, 177, 177, 177],\n",
      "        [429, 429, 429, 429, 429],\n",
      "        [472, 472, 472, 472, 472],\n",
      "        [214, 214, 214, 214, 214],\n",
      "        [155, 155, 155, 155, 155],\n",
      "        [240, 240, 240, 240, 240]]) torch.Size([8, 5])\n",
      "tensor([[False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False]])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "[tensor([0.]), tensor([0.])]\n"
     ]
    }
   ],
   "source": [
    "#randome int of batch size 8, from 500 classes\n",
    "\n",
    "topk = (1,5)\n",
    "batch_size = 8\n",
    "pred = torch.tensor([[402,  55, 366, 240, 440, 440, 418,  55],\n",
    "        [416, 108,  75, 366, 192, 309, 402, 108],\n",
    "        [129, 314, 197, 190, 486, 154, 355,  23],\n",
    "        [428,  75, 414, 341,  44, 143, 428, 314],\n",
    "        [ 81, 240, 320, 176, 416, 416, 201, 492]])\n",
    "print(pred, pred.shape)\n",
    "\n",
    "for idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "    pred = pred.t()\n",
    "    target = target.view(-1, 1)\n",
    "    print(target, target.shape)\n",
    "    target = target.expand_as(pred)\n",
    "    print(target, target.shape)\n",
    "\n",
    "    correct = pred.eq(target)\n",
    "    print(correct)\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        print(correct_k)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    \n",
    "    print(res)\n",
    "    break \n",
    "\n",
    "    # print(idx, data.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True])\n",
      "torch.Size([1])\n",
      "tensor([True])\n",
      "tensor([1.])\n",
      "tensor([True])\n",
      "tensor([ True, False, False, False, False])\n",
      "torch.Size([5])\n",
      "tensor([ True, False, False, False, False])\n",
      "tensor([1.])\n",
      "tensor([ True, False, False, False, False])\n",
      "[tensor([12.5000]), tensor([12.5000])]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "correct = torch.tensor([True, False, False, False, False, False, False, False],\n",
    "                       [False, False, False, False, False, False, False, False],\n",
    "                       [True, False, False, False, False, False, False, False])\n",
    "for k in topk:\n",
    "    print(correct[:k])\n",
    "    print(correct[:k].shape)\n",
    "    print(correct[:k].reshape(-1))\n",
    "    print(correct[:k].reshape(-1).float().sum(0, keepdim=True))\n",
    "    print(correct[:k].view(-1))\n",
    "    correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "    res.append(correct_k.mul_(100.0 / batch_size))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate(val_loader, model, classifier, criterion, opt, class_to_idx):\n",
    "    \"\"\"Validation\"\"\"\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    class_to_idx = val_loader.class_to_idx\n",
    "\n",
    "    \n",
    "\n",
    "    # Create dictionaries to store accuracy by race\n",
    "    race_acc = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (images, labels) in enumerate(val_loader):\n",
    "            images = images.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "\n",
    "            # Forward pass\n",
    "            output = classifier(model.encoder(images))\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # Update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
    "            top1.update(acc1[0], bsz)\n",
    "\n",
    "            # Measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # Group predictions and labels by race\n",
    "            for i in range(bsz):\n",
    "                label = labels[i].item()\n",
    "                predicted_class = output[i].argmax().item()\n",
    "                race = class_to_idx[label]\n",
    "\n",
    "                if race not in race_acc:\n",
    "                    race_acc[race] = AverageMeter()\n",
    "\n",
    "                race_acc[race].update(int(predicted_class == label), 1)\n",
    "\n",
    "            if idx % opt.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                       idx, len(val_loader), batch_time=batch_time,\n",
    "                       loss=losses, top1=top1))\n",
    "\n",
    "    print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "    # Print accuracy by race\n",
    "    for race, acc_meter in race_acc.items():\n",
    "        print(f'Race {race}: Acc@1 {acc_meter.avg:.3f}')\n",
    "\n",
    "    return losses.avg, top1.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'African': 0, 'Asian': 1, 'Caucasian': 2, 'Indian': 3}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main_linear import set_loader\n",
    "class Opt:\n",
    "    def __init__(self, val_folder, batch_size, num_workers, train_folder=None, model='resnet50', n_cls=4, ckpt='./path/to/your/ckpt/model.ckpt'):\n",
    "        self.val_folder = val_folder\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.train_folder = train_folder\n",
    "        self.model = model\n",
    "        self.n_cls = n_cls\n",
    "        self.ckpt = ckpt\n",
    "\n",
    "\n",
    "opt = Opt(val_folder='./data/linear_prob_data/train/', batch_size=32, num_workers=4)\n",
    "_, val_loader = set_loader(opt)\n",
    "class_to_idx = val_loader.dataset.class_to_idx\n",
    "class_to_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from main_linear import set_loader\n",
    "class Opt:\n",
    "    def __init__(self, val_folder, batch_size, num_workers, train_folder=None):\n",
    "        self.val_folder = val_folder\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.train_folder = train_folder\n",
    "\n",
    "opt = Opt(val_folder='./data/biased_african/train/', batch_size=32, num_workers=4)\n",
    "_, val_loader = set_loader(opt)\n",
    "class_to_idx = val_loader.dataset.class_to_idx\n",
    "class_to_idx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "{'African': 0, 'Asian': 1, 'Caucasian': 2, 'Indian': 3}\n",
    "\n",
    "\n",
    "I now want to see how i can modify validate code to record accuracy by race collect to \n",
    "1. Overall performance\n",
    "2. Inrace performance: Same race accuracy. Ex: We have 4 biased models and 1 of them is biased towards African dataset. We want to see just the perfomace on the African.\n",
    "3. Out of race performance: Other race accuracy. Ex: We have 4 biased models and 1 of them is biased towards African dataset. We want to see just the perfomace on the non-African or the performance on the 3 other races.\n",
    "\n",
    "Here is the validation and accuracy code, how would i modify them. I need to class_to_idx to track what inputs I am training on and what the validation is:\n",
    "\n",
    "\n",
    "\n",
    "def validate(val_loader, model, classifier, criterion, opt):\n",
    "    \"\"\"validation\"\"\"\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (images, labels) in enumerate(val_loader):\n",
    "            images = images.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "\n",
    "            # forward\n",
    "            output = classifier(model.encoder(images))\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
    "            top1.update(acc1[0], bsz)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if idx % opt.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                       idx, len(val_loader), batch_time=batch_time,\n",
    "                       loss=losses, top1=top1))\n",
    "\n",
    "    print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "    return losses.avg, top1.avg\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from util import AverageMeter, accuracy\n",
    "import time\n",
    "\n",
    "def validate(val_loader, model, classifier, criterion, opt, class_to_idx):\n",
    "    \"\"\"Validation\"\"\"\n",
    "    # model.eval()\n",
    "    # classifier.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    race_accuracies = {}  # Store accuracy by race\n",
    "    in_race_accuracies = {}  # Store in-race accuracy\n",
    "    out_of_race_accuracies = {}  # Store out-of-race accuracy\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (images, labels) in enumerate(val_loader):\n",
    "            images = images.float()\n",
    "            labels = labels\n",
    "            bsz = labels.shape[0]\n",
    "            # Debugging print: Print images, labels, and batch size\n",
    "            print(f'Batch {idx} - Images: {images.shape}, Labels: {labels.shape}, Batch Size: {bsz}')\n",
    "\n",
    "            # Check the shape of labels\n",
    "            print(f'Labels Shape: {labels.shape}')\n",
    "            # Calculate the race for each image based on class labels\n",
    "            race_labels = [k for k, v in class_to_idx.items() if v in labels]\n",
    "            race_labels = []\n",
    "            for k, v in class_to_idx.items():\n",
    "                print(k)\n",
    "                print(v)\n",
    "\n",
    "\n",
    "                if v in labels:\n",
    "                    race_labels.append(k)\n",
    "            print(f'Race Labels: {race_labels}')\n",
    "\n",
    "            return\n",
    "\n",
    "            # Debugging print: Print the current batch index and batch size\n",
    "            # Forward pass\n",
    "            # output = classifier(model.encoder(images))  # Commented out the encoder part\n",
    "            output = classifier(images)  # Assuming 'classifier' is appropriate for the task\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # Debugging print: Print the loss and accuracy for this batch\n",
    "            print(f'Loss: {loss.item()}, Accuracy: {accuracy(output, labels)}')\n",
    "\n",
    "            # Update metrics\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1, _ = accuracy(output, labels, topk=(1, 5))\n",
    "            top1.update(acc1, bsz)\n",
    "\n",
    "            # Debugging print: Print the updated metrics\n",
    "            print(f'Updated Loss: {losses.avg}, Updated Accuracy: {top1.avg}')\n",
    "\n",
    "            # Calculate accuracy by race\n",
    "            for race in race_labels:\n",
    "                if race not in race_accuracies:\n",
    "                    race_accuracies[race] = AverageMeter()\n",
    "                race_accuracies[race].update(acc1, bsz)\n",
    "\n",
    "            # Debugging print: Print accuracy by race\n",
    "            print(f'Accuracy by Race: {race_accuracies}')\n",
    "\n",
    "            # Measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                       idx, len(val_loader), batch_time=batch_time,\n",
    "                       loss=losses, top1=top1))\n",
    "\n",
    "    print(' * Overall Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "    # Calculate in-race and out-of-race accuracy\n",
    "    for race, accuracy_meter in race_accuracies.items():\n",
    "        in_race_acc = accuracy_meter.avg\n",
    "        out_of_race_acc = (top1.avg * bsz - accuracy_meter.sum) / (bsz - accuracy_meter.count)\n",
    "        in_race_accuracies[race] = in_race_acc\n",
    "        out_of_race_accuracies[race] = out_of_race_acc\n",
    "\n",
    "        # Debugging print: Print in-race and out-of-race accuracy\n",
    "        print(f'In-Race Accuracy ({race}): {in_race_acc:.3f}')\n",
    "        print(f'Out-of-Race Accuracy ({race}): {out_of_race_acc:.3f}')\n",
    "\n",
    "    # Debugging print: Print the final accuracy results\n",
    "    print(f'Final Loss: {losses.avg}, Final Accuracy: {top1.avg}')\n",
    "    print(f'Final In-Race Accuracy: {in_race_accuracies}')\n",
    "    print(f'Final Out-of-Race Accuracy: {out_of_race_accuracies}')\n",
    "\n",
    "    return losses.avg, top1.avg, in_race_accuracies, out_of_race_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from main_linear import set_loader  # Replace with your actual data loader module\n",
    "from networks.resnet_big import LinearClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from networks.resnet_big import SupConResNet, LinearClassifier\n",
    "\n",
    "def set_model(opt):\n",
    "    model = SupConResNet(name=opt.model)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    classifier = LinearClassifier(name=opt.model, num_classes=opt.n_cls)\n",
    "\n",
    "    ckpt = torch.load(opt.ckpt, map_location='cpu')\n",
    "    state_dict = ckpt['model']\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model.encoder = torch.nn.DataParallel(model.encoder)\n",
    "        else:\n",
    "            new_state_dict = {}\n",
    "            # for k, v in state_dict.items():\n",
    "            #     k = k.replace(\"module.\", \"\")\n",
    "            #     new_state_dict[k] = v\n",
    "            # state_dict = new_state_dict\n",
    "            # model = model.cuda()\n",
    "            # classifier = classifier.cuda()\n",
    "            # criterion = criterion.cuda()\n",
    "            # cudnn.benchmark = True\n",
    "\n",
    "        # model.load_state_dict(state_dict)\n",
    "    else:\n",
    "        print(\"GPU not available. Using CPU for inference.\")\n",
    "        model.load_state_dict(state_dict, map_location='cpu')\n",
    "\n",
    "    return model, classifier, criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the Opt object\n",
    "class Opt:\n",
    "    def __init__(self, val_folder, batch_size, num_workers, train_folder=None):\n",
    "        self.val_folder = val_folder\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.train_folder = train_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzomendoza/anaconda3/envs/machinelearning/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/lorenzomendoza/anaconda3/envs/machinelearning/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 - Images: torch.Size([10, 3, 400, 400]), Labels: torch.Size([10]), Batch Size: 10\n",
      "Labels Shape: torch.Size([10])\n",
      "African\n",
      "0\n",
      "Asian\n",
      "1\n",
      "Caucasian\n",
      "2\n",
      "Indian\n",
      "3\n",
      "Race Labels: ['African']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m small_val_loader\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39msamples \u001b[39m=\u001b[39m small_val_loader\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39msamples[:num_samples_to_test]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Call the modified validate function with the small test dataset\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss, overall_accuracy, in_race_accuracies, out_of_race_accuracies \u001b[39m=\u001b[39m validate(val_loader, model, classifier, criterion, opt, class_to_idx)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# # Print the results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# print(f'Overall Accuracy: {overall_accuracy:.3f}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# for race, in_race_acc in in_race_accuracies.items():\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#     print(f'In-Race Accuracy ({race}): {in_race_acc:.3f}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzomendoza/Documents/CS_Courses/Current/CSC_277/project/SupContrast-ORE/testing.ipynb#X34sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m#     print(f'Out-of-Race Accuracy ({race}): {out_of_race_accuracies[race]:.3f}')\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from main_linear import set_loader  # Replace with your actual data loader module\n",
    "from networks.resnet_big import LinearClassifier\n",
    "# Load your model and data loaders\n",
    "# model = models.resnet50(pretrained=True)\n",
    "# classifier = nn.Linear(2048, 4)  # Replace with your classifier architecture\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "opt = Opt(val_folder='./data/linear_prob_data/train/', batch_size=32, num_workers=4)\n",
    "\n",
    "# Load the data loader\n",
    "_, val_loader = set_loader(opt)\n",
    "\n",
    "# Define class_to_idx based on your dataset\n",
    "class_to_idx = {'African': 0, 'Asian': 1, 'Caucasian': 2, 'Indian': 3}\n",
    "# Iterate through the small validation data loader and print labels\n",
    "# for idx, (images, labels) in enumerate(val_loader):\n",
    "#     print(f'Batch {idx} - Labels: {labels}')\n",
    "\n",
    "\n",
    "# Create a small test dataset by taking the first N samples from the validation set\n",
    "num_samples_to_test = 10  # Adjust this number as needed\n",
    "small_val_loader = torch.utils.data.DataLoader(val_loader.dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n",
    "small_val_loader.dataset.samples = small_val_loader.dataset.samples[:num_samples_to_test]\n",
    "\n",
    "# Call the modified validate function with the small test dataset\n",
    "loss, overall_accuracy, in_race_accuracies, out_of_race_accuracies = validate(val_loader, None, None, None, opt, class_to_idx)\n",
    "\n",
    "# # Print the results\n",
    "# print(f'Overall Accuracy: {overall_accuracy:.3f}')\n",
    "# for race, in_race_acc in in_race_accuracies.items():\n",
    "#     print(f'In-Race Accuracy ({race}): {in_race_acc:.3f}')\n",
    "#     print(f'Out-of-Race Accuracy ({race}): {out_of_race_accuracies[race]:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
